{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5e4fcb-4335-4572-b466-59d6841c83d6",
   "metadata": {},
   "source": [
    "# Mapping Coordinates\n",
    "As mentioned in the previous section, our aim with registration is to find a coordinate mapping between the *source* image and the *target* image. Given our discussions last week about using affine transformation matrices to covert coordinates, an obvious place to start is with registration methods that use affine methods to map between images. In this section, we will expand on the content from last week to see how we can use the matrices in the image headers to map the coordinates of one image into the coordinates of another image.\n",
    "\n",
    "Note that registration using affine transformations is known as *linear* registration. This means we do not have free reign to align the images however we like. We cannot bend any element of the image and we cannot use different transformations in different parts of the brain. Instead, we are restricted to only being able to *translate*, *rotate*, *scale* or *shear* the images to get them to line-up. For some registration tasks, such as motion correction, this makes sense, whereas for other tasks we may need something more flexible. At the end of this lesson, we will discuss an alternative approach known as *non-linear* registration, that offers greater flexibility at a cost of greater complexity.\n",
    "\n",
    "## Using the $\\mathbf{Q}$ Matrix for Mapping\n",
    "Last week, we saw how to define a matrix $\\mathbf{Q}$ that can map between the voxel coordinates in an image and a transformed version of those coordinates, using a transformation matrix$\\mathbf{T}$\n",
    "\n",
    "$$\n",
    "\\mathbf{Q} = (\\mathbf{TM})^{-1}\\mathbf{M}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{M}$ is the voxel-to-world matrix from the image header. We also noted that this works because it turns the voxel coordinates into millimetres, applies the transformation in world-space and then converts the millimetre coordinates back into voxel coordinates. This makes sense because it is more intuitive to transform an image using real-world units, such as millimetres and degrees. Similarly, if we want to map coordinates between two different images, it makes sense to do this in world-space. This is because two images can be different dimensions, resolutions and orientations, yet we can still find the same millimetre location in each one thanks to the matrices in the header. World-space is therefore a *common coordinate system*, irrespective of the image in question.\n",
    "\n",
    "To achieve this, we can adapt the definition of Q to be\n",
    "\n",
    "$$\n",
    "\\mathbf{Q} = (\\mathbf{TM}_{S})^{-1}\\mathbf{M}_{T}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{M}_{S}$ is the header matrix from the *source* image and $\\mathbf{M}_{T}$ is the header matrix from the *target* image. So what does this new version of $\\mathbf{Q}$ do? If we assume that $\\mathbf{x}$ represents voxel coordinates from the target image, then the operation $\\mathbf{Qx}$ will first transform the voxel coordinates to millimetres using $\\mathbf{M}_{T}$, then convert the millimetre coordinates to voxel coordinates in the source image using the inverse of $\\mathbf{TM}_{S}$. So the important point here is that this form of $\\mathbf{Q}$ will take voxel coordinates in one image and turn them into voxel coordinates in the other image. This is achieved by matched the images using the same millimetre coordinates in world-space. \n",
    "\n",
    "In addition, the definition of $\\mathbf{Q}$ above also include a transformation $\\mathbf{T}$ that can be used to adjust for any misalignment between the image. However, when we first collect these images we do not know if any transformation is necessary. As such, we have to start by considering the default mapping between the images. We can do this by setting the matrix $\\mathbf{T}$ to be the identity, which is equivalent to no transformation. If we do this then $\\mathbf{T}$ drops out of the equation and we have \n",
    "\n",
    "$$\n",
    "\\mathbf{Q} = (\\mathbf{M}_{S})^{-1}\\mathbf{M}_{T}\n",
    "$$\n",
    "\n",
    "which gives us our starting point for image registration. \n",
    "\n",
    "As an example, consider the following MATLAB code which loads the header matrices for the functional and anatomical images used in the previous section. The code computes $\\mathbf{Q}$ using the definition above. $\\mathbf{Q}$ is then used to find out which voxel in the source matches voxel $[87, 182, 127]$ from the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791deafd-d70b-453e-bf8d-edd81472ced9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><pre>ans = 4×1 double\n",
       "    4.7972\n",
       "   48.4056\n",
       "   20.1250\n",
       "    1.0000\n",
       "</pre></body></html>"
      ],
      "text/plain": [
       "ans = 4×1 double\n",
       "    4.7972\n",
       "   48.4056\n",
       "   20.1250\n",
       "    1.0000\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdr_anat = spm_data_hdr_read('sub-01_T1w.nii');\n",
    "hdr_func = spm_data_hdr_read('sub-01_task-flanker_run-1_bold.nii,1');\n",
    "\n",
    "Mt = hdr_anat.mat;\n",
    "Ms = hdr_func.mat;\n",
    "\n",
    "Q = inv(Ms) * Mt;\n",
    "Q * [87 182 127 1]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1327aa7d-9780-4e95-88dc-f20fb4f4c4f9",
   "metadata": {},
   "source": [
    "According to this calculation, the matching voxel in the source image is $[4.7972, 48.4056, 20.1250]$. \n",
    "\n",
    "To see why, we can calculate the millimetre coordinates for voxel $[87, 182, 127]$ from the target image and the millimetre coordinates for voxel $[4.7972, 48.4056, 20.1250]$ from the source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a98be9c7-ad0c-4943-ad0d-0eb624074937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><body><pre>ans = 4×1 double\n",
       "  -83.8313\n",
       "   52.0542\n",
       "   -1.5000\n",
       "    1.0000\n",
       "</pre></body></html>"
      ],
      "text/plain": [
       "ans = 4×1 double\n",
       "  -83.8313\n",
       "   52.0542\n",
       "   -1.5000\n",
       "    1.0000\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<html><body><pre>ans = 4×1 double\n",
       "  -83.8313\n",
       "   52.0541\n",
       "   -1.5000\n",
       "    1.0000\n",
       "</pre></body></html>"
      ],
      "text/plain": [
       "ans = 4×1 double\n",
       "  -83.8313\n",
       "   52.0541\n",
       "   -1.5000\n",
       "    1.0000\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mt * [87     182     127    1]'\n",
    "Ms * [4.7972 48.4056 20.125 1]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d10b602-8b06-4f28-aeaf-4df2cd4bbe51",
   "metadata": {},
   "source": [
    "So we can see that the reason these voxels are matched is because they share the same millimetre coordinates. It is notable as well that converting voxel coordinates between these images has lead to fractional voxel indices for the source image. As such, we would need to use some form of interpolation to make use of this mapping, as discussed last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35655167-0811-46a0-8c59-f9db04dcb124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB Kernel",
   "language": "matlab",
   "name": "jupyter_matlab_kernel"
  },
  "language_info": {
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
